{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gQ6hfdwLcVTe",
   "metadata": {
    "id": "gQ6hfdwLcVTe"
   },
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8caf065-9b4f-401b-8f34-fc345b1813b0",
   "metadata": {
    "id": "e8caf065-9b4f-401b-8f34-fc345b1813b0"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IWj5fnDMdDnf",
   "metadata": {
    "id": "IWj5fnDMdDnf"
   },
   "source": [
    "## Load Data from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da4e3a7-2266-494b-8a5b-618f0851ad89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "fed0dfc1ec0f47be83fcd750a08bb4c5",
      "6ffc218ab9064dcf846216b452f2b6bd",
      "48146e8e177d427b807a39c76f7f4850",
      "e0c4c41fb96f40e6af8ec69b837cccac",
      "1cbd02aec81544e7885ccb4ce338e635",
      "2ccc53093e0d4a96887ffaf84bf1d18c",
      "b1edf5c1e9ee45409846cfb69866d463",
      "8aef497a7c544db0ad68fe1154e15c01",
      "fbdd2cc37500427b982e0fd0cb03185e",
      "06fce8eaa76f48dd8d9d72b2fe5e4070",
      "c72e698a96d14bd888a26a0144d60291",
      "1019718579dd454cb89518b32c35fd56",
      "e407600708dd4978a3cb953fdbe5b104",
      "ec0353e4a9a740d1b005652362ec3e96",
      "32a5a25db5804ce794878a47599c4316",
      "b2764aa14e7a4090886283c0c0bcc8ff",
      "757fc26872304a899837d37a993ae8d2",
      "1cb65eb6e37d431abaa7d390f3b29a76",
      "4cdd69f282fc4da29a2f5857d9f245e4",
      "198e2d839b8e4870a7d34dee544ceb15",
      "4065f5f463d541f98f8d28da25808928",
      "6448537753524235a3c135e750622484",
      "ccaf8663a15f48de8e4211d2c03daa05",
      "4087c039f97e4964ac6ba4caced99f2a",
      "fd350f2357a34552aae76f08e5bfd6b6",
      "0a486a84f3b946978f9d639a8625e4de",
      "0703096dce4343388b4a8673ab599e67",
      "2334814eb69f4365816e1b7f9ac2f35a",
      "94120541eb594b488a9807dbba6f582b",
      "c089c78aef6949a2a856d2f1f262af9e",
      "cd5e0a8439bd4ba8a4de76917ddd07ed",
      "03eec16e076c4a39a13822a4d7372367",
      "8a6719775bd64effa2b07c1ade02dbf5",
      "43e45d3903ef45f794bb8555787da247",
      "4474231e0eb74150a3cef8e25eddf220",
      "9987ed622cbd4180978aa43e690c5721",
      "157d12f2988742f7ac6af2c253c4f79e",
      "62b0d7eb6b7c4691bdbe5efc710a4e0b",
      "1d542e8569424a4ba9f5ba2d88260a50",
      "7061ea8382bf4719b28a8f813a630f3c",
      "38ef1f70aa49400d9825bc606651b64f",
      "759b44434aa5449189e3309583980ff1",
      "1e535f7ff79843bd9b2961bc6cb34be9",
      "479708d51ca044bf8b68646870bd1752",
      "78d96b1ce87e42f0afde8a3130e112ab",
      "44ef99b3092e4cd88b937583f96a80cd",
      "7404a2f1171746d9b9f9efca32463495",
      "3c3fb53e581646739b502e9aa677fd26",
      "fff67780be4c44f593b789fed1c4052f",
      "d071f8e83e31412abe0041149fe0823e",
      "7b271fd53ab24bcc88da3a2de261f187",
      "18daf02eaf354d78a2115e1eb861a3ae",
      "2efa8e85af9240b3a965af6499869805",
      "d7b2bf898b164c6996b637b39f62c8a5",
      "c20e168c3ddb4003885c853aa080a7e4",
      "394277d9037c408b9abcd4425c55d8cb",
      "7518cf2f529e49ebb427ac194aeff7a8",
      "5f2924f005134525800a4018cae2eaff",
      "2bf1bd7f224d45209ddd59543d50cb5e",
      "3906eff685e0461e92bea9c2b72b51be",
      "3af074d034bc4f7d81594ab28dbddd69",
      "f2267991f0d9427c8e8fe94b54ab55e5",
      "9a949eeecfc44ea6865b0c3b87e0f27d",
      "29228556f485495dbadaf8f329a0c4f7",
      "f6c653cd1704491f98756ea60ce10d53",
      "310872e0bcf14f83a249cc25b3aabd42"
     ]
    },
    "id": "7da4e3a7-2266-494b-8a5b-618f0851ad89",
    "outputId": "28e8fc51-c834-4301-81de-2250ca204bc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed0dfc1ec0f47be83fcd750a08bb4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/9.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1019718579dd454cb89518b32c35fd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/12.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccaf8663a15f48de8e4211d2c03daa05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e45d3903ef45f794bb8555787da247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d96b1ce87e42f0afde8a3130e112ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394277d9037c408b9abcd4425c55d8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"conll2003\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f78dc97-ae0f-4cde-8e58-70a2e477a87e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f78dc97-ae0f-4cde-8e58-70a2e477a87e",
    "outputId": "75d1307b-95ea-4345-d8f4-fba859f9fba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28613360-19e1-4023-96f0-1f681ea594ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28613360-19e1-4023-96f0-1f681ea594ff",
    "outputId": "e2c30cfa-783b-41bb-8440-656196b43e7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (14041, 5), 'validation': (3250, 5), 'test': (3453, 5)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4f2306d-e3d8-47fd-9a04-43048d09429a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4f2306d-e3d8-47fd-9a04-43048d09429a",
    "outputId": "8bf278f1-4b92-4040-b489-92de78511f1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0473b67c-6d60-43ed-81bf-df79ae236db7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0473b67c-6d60-43ed-81bf-df79ae236db7",
    "outputId": "4c7f8af2-49f1-4cb2-edf2-9322d95c73c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac7961e-ecc3-4c61-a14e-0d662d5f091a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ac7961e-ecc3-4c61-a14e-0d662d5f091a",
    "outputId": "36e9773e-45da-45fe-82e1-624f13622e1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"].features[\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0b185-f124-46ae-8071-2ca3d3cdef19",
   "metadata": {
    "id": "1de0b185-f124-46ae-8071-2ca3d3cdef19",
    "outputId": "721ceb40-1f14-46f2-e275-0f1e6ab18fdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Tdgrxi95djLK",
   "metadata": {
    "id": "Tdgrxi95djLK"
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb7798e8-1691-4720-9a31-7afa56372356",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "a4d03df7a7e3402893bafddd0b6e3766",
      "6f4e853fb79a45b6be8b560a284a72bf",
      "cad4b4649a364c40ae363314b48074da",
      "faf30c233b184dceaeb12e561d112650",
      "9db243819dff44858af09383a83b3ead",
      "9f96344c08dd4a63b505f10e41eef85a",
      "865aab32a3fa4b6b864b84a9d4bc7929",
      "182f8b8612494a0ea5e635070a80ffad",
      "1524e9d234ab4a819fb9e4c686e6b242",
      "d598fe143bd4468397bdd3654108f388",
      "d92190d0167f4bdaa58a717df71b5520",
      "7446e8760fb7425da2c9fa4686fee1db",
      "209694b43662435b863ad8cbfe0721d4",
      "24590120ac434e98804e225f615b4fe0",
      "f3f026cd336042d0b0194623332153ff",
      "e9b67a17da9f4f809314aa75d96c8a8a",
      "adf794e97f454d4ba05851f90d8d01b8",
      "8fb50f3620f04a568440e99fee32903d",
      "1c5817f534b34950beec0d1a55544b51",
      "d22b0d06bd0141269b6feb106fc5f604",
      "04c2a65766804e4b99f87b7a16811b94",
      "14bf06394c7742f7a95316f6cfdc2b5b",
      "324417f407bd46bc81239d7d34ac9eb6",
      "0ced7659ac714e7cbcc05e56cf16915a",
      "53830d2ae7864ba9965b7bebcce1fb7b",
      "8a8f470e82f44622844d45217964761e",
      "8123d8d949ba4c1ca567fd2798d10230",
      "3b70285ccc11435ebb3cf698e0787f91",
      "9122eb3835b7480da66866af8113e045",
      "dab80862e1a3415a8b94b6c8ffca0540",
      "c4c262ee5179495092c8f863d9b94c6c",
      "8c76f1f768dc47dcb8e934ef56147431",
      "2ef2552b5d5441d6a530b2aac53055c5",
      "e646f5d9e9cc4762b9f6fbc98a99b533",
      "fd7716a2f32d483cad2d29314b5e6897",
      "6729be391d9543a9a2c4e17cb9da2fc9",
      "5703f9650ff044648fbffb3dd3ecacdb",
      "630411de11074038a4ecf5edccbc9bda",
      "6bc8dae541ea4bcb84c63183bd221e35",
      "3a323bdb921a4c69bafda5a04bc7eb99",
      "3e2be671cdd8484699c987f3b00cce50",
      "58dbf7191bd346c09c57f6209f5dee19",
      "53f4639148b34f91afb724857dcdf5a9",
      "1a312d47798740bab8fcfdb038fdaae2"
     ]
    },
    "id": "eb7798e8-1691-4720-9a31-7afa56372356",
    "outputId": "8d16d6d6-074a-4e38-aab9-8f070cc9187c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d03df7a7e3402893bafddd0b6e3766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7446e8760fb7425da2c9fa4686fee1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324417f407bd46bc81239d7d34ac9eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e646f5d9e9cc4762b9f6fbc98a99b533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  used to convert text into a format that a BERT model can understand, process and tokenize text for input into a BERT model.\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5da782c-d85d-4bd6-a6c4-dd1586c9f9c9",
   "metadata": {
    "id": "b5da782c-d85d-4bd6-a6c4-dd1586c9f9c9"
   },
   "outputs": [],
   "source": [
    "ex = raw_datasets['train'][0]\n",
    "# get sequences of ex text\n",
    "tokenized_input = tokenizer(ex['tokens'], is_split_into_words=True)\n",
    "# return each number to it's word\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input['input_ids'])\n",
    "# words inddices\n",
    "word_ids = tokenized_input.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271e535-0715-4e3b-a5b2-639df5e74a9c",
   "metadata": {
    "id": "f271e535-0715-4e3b-a5b2-639df5e74a9c",
    "outputId": "fc82aab6-3fdf-4f85-d5c8-1d3bfae755b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ex['ner_tags']), len(tokenized_input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b96f815-19c9-46ef-9ca6-6a56138a6aee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "9b96f815-19c9-46ef-9ca6-6a56138a6aee",
    "outputId": "e161c871-01d3-4a73-ffd4-4e6aa4e5f08f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\ninput ids return by tokenizer longer than labels,\\nbecouse special chars or tokenizer may split any word into multiple tokens\\nso will build tokenize_and_align_labels function to handle this problem\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "input ids return by tokenizer longer than labels,\n",
    "becouse special chars or tokenizer may split any word into multiple tokens\n",
    "so will build tokenize_and_align_labels function to handle this problem\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "473067e0-09cd-47b5-9087-0dbf011b4fd0",
   "metadata": {
    "id": "473067e0-09cd-47b5-9087-0dbf011b4fd0"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        # word_ids() => Return a list mapping the tokens\n",
    "        # to their actual word in the initial sentence.\n",
    "        # It Returns a list indicating the word corresponding to each token.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        # Special tokens like `<s>` and `<\\s>` are originally mapped to None\n",
    "        # We need to set the label to -100 so they are automatically ignored in the loss function.\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                # set â€“100 as the label for these special tokens\n",
    "                label_ids.append(-100)\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # if current word_idx is != prev then its the most regular case\n",
    "                # and add the corresponding token\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                # to take care of sub-words which have the same word_idx\n",
    "                # set -100 as well for them, but only if label_all_tokens == False\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "                # mask the subword representations after the first subword\n",
    "\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "171e8d8c-6bd7-4eef-b8f1-4b7f40ae8981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "171e8d8c-6bd7-4eef-b8f1-4b7f40ae8981",
    "outputId": "4006e010-3ec3-4664-b6db-4e3d393c94f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.']\n",
      "{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}\n"
     ]
    }
   ],
   "source": [
    "q = tokenize_and_align_labels(raw_datasets['train'][4:5])\n",
    "print(raw_datasets['train'][4]['tokens'])\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e2082-d3d9-4ac9-a1e8-c33be8199177",
   "metadata": {
    "id": "841e2082-d3d9-4ac9-a1e8-c33be8199177",
    "outputId": "11c71825-39e5-4d63-8d9e-53b909798a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]___________________________________ -100\n",
      "germany_________________________________ 5\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "representative__________________________ 0\n",
      "to______________________________________ 0\n",
      "the_____________________________________ 0\n",
      "european________________________________ 3\n",
      "union___________________________________ 4\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "veterinary______________________________ 0\n",
      "committee_______________________________ 0\n",
      "werner__________________________________ 1\n",
      "z_______________________________________ 2\n",
      "##wing__________________________________ 2\n",
      "##mann__________________________________ 2\n",
      "said____________________________________ 0\n",
      "on______________________________________ 0\n",
      "wednesday_______________________________ 0\n",
      "consumers_______________________________ 0\n",
      "should__________________________________ 0\n",
      "buy_____________________________________ 0\n",
      "sheep___________________________________ 0\n",
      "##me____________________________________ 0\n",
      "##at____________________________________ 0\n",
      "from____________________________________ 0\n",
      "countries_______________________________ 0\n",
      "other___________________________________ 0\n",
      "than____________________________________ 0\n",
      "britain_________________________________ 5\n",
      "until___________________________________ 0\n",
      "the_____________________________________ 0\n",
      "scientific______________________________ 0\n",
      "advice__________________________________ 0\n",
      "was_____________________________________ 0\n",
      "clearer_________________________________ 0\n",
      "._______________________________________ 0\n",
      "[SEP]___________________________________ -100\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(q[\"input_ids\"][0]),q[\"labels\"][0]):\n",
    "    print(f\"{token:_<40} {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e463ec1-9401-479b-a057-5d228b232004",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "8f99169159c9436aa17c7276defa1a4e",
      "20d2df932b374c7b9f6c20cef69d7cb2",
      "46472084ec2d475dac41fdd671862296",
      "7161fb63daec4ddb9177a28c5d81a3da",
      "9a7ef9d8dc874990a5737b3579086d70",
      "efdc413ab82c4025b751f721814f8971",
      "3b1a7d13dbc2413eb25d95f6e347a45c",
      "0c972fe93e434849845889491586dd76",
      "8f6f55bb2a8747569fe3a7b52e2524d1",
      "72dc4d6b91b240fa9d2a6554c4d7b992",
      "2bc1d8bd8e9b4b8f9455b48b07ecc567",
      "55e98928acc94d23ac7f98abedb37726",
      "bf5753518a2b41d29ffc82adb2b3a778",
      "83e7cb6be9e24279bdb277000736a503",
      "2de5e260585940eeb6f00ee1c7b3bd2d",
      "9e82fcd4fecd4a2db7e6074216ffbf1c",
      "f31c6ab73a4448c68bfc341be724798d",
      "4cf1849222014ff8a5d7b5e1849409ed",
      "bb3b78cc81a74cc2af44aca205d651eb",
      "fdef85b876d84349b9bd9ccf8c724b78",
      "298a427bb9514b06990f761f8117714f",
      "3595210c04b443f8b0ae0c68e0cc5e6d",
      "943e478391f743f3b64bda354bc847e0",
      "7e18b4ebac8444378d32008a86fc0f60",
      "38337651b6094af2b42281e576d2eab9",
      "e6be36c6df1e45f5ab0388964044d3be",
      "68e912e9f1ca40c799515d7b9ae8f95a",
      "8ab04b9783e046e0a753e3905bcbba07",
      "ec157398907e45ff87bba69e0e276200",
      "3f6e2689a42e46beb17917137472903e",
      "853065a1da6e4489a5a337d9e6f213d1",
      "c3259978d8624989a066335db162a343",
      "90836a9cad364be38cf6d8925d92a6a4"
     ]
    },
    "id": "3e463ec1-9401-479b-a057-5d228b232004",
    "outputId": "bd4bfe63-fc07-49ba-d89e-2209f453017d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f99169159c9436aa17c7276defa1a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e98928acc94d23ac7f98abedb37726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943e478391f743f3b64bda354bc847e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# map tokenizer to all data set\n",
    "tokenized_datasets = raw_datasets.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3RrquM43e8TW",
   "metadata": {
    "id": "3RrquM43e8TW"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ddeb279-b89a-432b-bcc7-003e74ebdc56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "6b1116609ea64c8aab41e048c6b4c75e",
      "4fbd9f8cca0847e2b35efcd453a07d06",
      "4e9d1db9112043bfbe0238ddd12614e9",
      "6727894775404e1b83fec748e065dbb7",
      "48d470a7df6649759afe656a3371ba3f",
      "a8c88b4cc92948afa2d0896fcef4c74e",
      "23b91310720546cfabb36182abbbce0a",
      "4bed991dc1594e07a103aa9664080c79",
      "f5daaa54357b42d2bd8bc6ac7e80720b",
      "70251bb215cc4ed6925daf52d351fe36",
      "9121d28939ad40248600c2c119c6cd71"
     ]
    },
    "id": "7ddeb279-b89a-432b-bcc7-003e74ebdc56",
    "outputId": "f772fd43-1d8a-40c2-e9b2-57d014c45ea4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1116609ea64c8aab41e048c6b4c75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35fa431d-4cac-4c24-95c6-631b18c0342e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35fa431d-4cac-4c24-95c6-631b18c0342e",
    "outputId": "6613c653-7adc-479e-a9bd-af69ea47238f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "args = TrainingArguments(\n",
    "    \"test-ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e943033-9b46-40ec-8eba-a25a7f3aebd2",
   "metadata": {
    "id": "2e943033-9b46-40ec-8eba-a25a7f3aebd2"
   },
   "outputs": [],
   "source": [
    "# automatically padding some model inputs to the length of the longest example\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5f765f6-6bc2-4c93-888f-28cd6548b0c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "34b5d68901eb4cca806006e1eb3ae3c4",
      "e38d8887eae34ed9bdf6f309adfcb8f1",
      "20026f781c2248c2b7b1adf49f7f4376",
      "da94bb7e41a64650a28d8a59fcdc0943",
      "cf1329f5fefc42f18b8053d858f6c2fd",
      "c8fed74fce154a6296ee8861a0360354",
      "29f2d9bdc0cf4224a90223de6dccce28",
      "eb431875a42d452ca369b549dc10b3ea",
      "cb4100fcccdc40de9a6c608f9f489d89",
      "9190be1a148a436291e645bc80fe17d6",
      "b778437b5aa84716a0389b9f0a188887"
     ]
    },
    "id": "b5f765f6-6bc2-4c93-888f-28cd6548b0c1",
    "outputId": "2623bbbf-7c58-4eb5-af49-6ac08e3d278e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-ca4db3689d00>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric(\"seqeval\", trust_remote_code=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b5d68901eb4cca806006e1eb3ae3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = datasets.load_metric(\"seqeval\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b514022d-cbc0-47e1-b220-b7c4af0afc81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b514022d-cbc0-47e1-b220-b7c4af0afc81",
    "outputId": "ee2d73cc-1e57-4271-aafa-542a2c124cd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = raw_datasets['train'][0]\n",
    "label_list = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad49cb99-b07d-41e3-aef8-e35bb76a750b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad49cb99-b07d-41e3-aef8-e35bb76a750b",
    "outputId": "a7c9e2d2-bf8c-4ddd-e0a6-f9ed51f9f784"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give example on metric\n",
    "labels = [label_list[i] for i in example[\"ner_tags\"]]\n",
    "\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "343a8d4e-0286-45cd-9c3d-ceda138e80bb",
   "metadata": {
    "id": "343a8d4e-0286-45cd-9c3d-ceda138e80bb"
   },
   "outputs": [],
   "source": [
    "# control output function\n",
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"\n",
    "    Function to compute the evaluation metrics for Named Entity Recognition (NER) tasks.\n",
    "    The function computes precision, recall, F1 score and accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    eval_preds (tuple): A tuple containing the predicted logits and the true labels.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing the precision, recall, F1 score and accuracy.\n",
    "    \"\"\"\n",
    "    pred_logits, labels = eval_preds\n",
    "\n",
    "    pred_logits = np.argmax(pred_logits, axis=2)\n",
    "    # the logits and the probabilities are in the same order,\n",
    "    # so we donâ€™t need to apply the softmax\n",
    "\n",
    "    # We remove all the values where the label is -100\n",
    "    predictions = [\n",
    "        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(pred_logits, labels)\n",
    "    ]\n",
    "\n",
    "    true_labels = [\n",
    "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
    "       for prediction, label in zip(pred_logits, labels)\n",
    "   ]\n",
    "    results = metric.compute(predictions=predictions, references=true_labels)\n",
    "    return {\n",
    "   \"precision\": results[\"overall_precision\"],\n",
    "   \"recall\": results[\"overall_recall\"],\n",
    "   \"f1\": results[\"overall_f1\"],\n",
    "  \"accuracy\": results[\"overall_accuracy\"],\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3185a269-bd35-4683-95f1-6351e1292955",
   "metadata": {
    "id": "3185a269-bd35-4683-95f1-6351e1292955"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "   train_dataset=tokenized_datasets[\"train\"],\n",
    "   eval_dataset=tokenized_datasets[\"validation\"],\n",
    "   data_collator=data_collator,\n",
    "   tokenizer=tokenizer,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67c40424-1f73-4988-92c1-478b6d52af75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "67c40424-1f73-4988-92c1-478b6d52af75",
    "outputId": "87aa0dd8-7f4f-41c2-d8f8-4df401007631"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2634/2634 08:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.065597</td>\n",
       "      <td>0.912469</td>\n",
       "      <td>0.920125</td>\n",
       "      <td>0.916281</td>\n",
       "      <td>0.981302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.058881</td>\n",
       "      <td>0.929512</td>\n",
       "      <td>0.939702</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.984670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.058095</td>\n",
       "      <td>0.936489</td>\n",
       "      <td>0.945184</td>\n",
       "      <td>0.940816</td>\n",
       "      <td>0.985702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/vocab.txt',\n",
       " 'tokenizer/added_tokens.json',\n",
       " 'tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained(\"ner_model\")\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H85s4zJMfgo8",
   "metadata": {
    "id": "H85s4zJMfgo8"
   },
   "source": [
    "## Load Fine Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efa70a06-8167-410b-8e91-bc6339dee62f",
   "metadata": {
    "id": "efa70a06-8167-410b-8e91-bc6339dee62f"
   },
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    str(i): label for i,label in enumerate(label_list)\n",
    "}\n",
    "label2id = {\n",
    "    label: str(i) for i,label in enumerate(label_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "MmHCDlEJLvKT",
   "metadata": {
    "id": "MmHCDlEJLvKT"
   },
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "vXnG46vIL32D",
   "metadata": {
    "id": "vXnG46vIL32D"
   },
   "outputs": [],
   "source": [
    "config = json.load(open(\"ner_model/config.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "JtEeqELjL6wy",
   "metadata": {
    "id": "JtEeqELjL6wy"
   },
   "outputs": [],
   "source": [
    "config[\"id2label\"] = id2label\n",
    "config[\"label2id\"] = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "w2DkCKDUL-aN",
   "metadata": {
    "id": "w2DkCKDUL-aN"
   },
   "outputs": [],
   "source": [
    "json.dump(config, open(\"ner_model/config.json\",\"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "uwTuRcTJMDwy",
   "metadata": {
    "id": "uwTuRcTJMDwy"
   },
   "outputs": [],
   "source": [
    "model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"ner_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TmcT9BuIhpCq",
   "metadata": {
    "id": "TmcT9BuIhpCq"
   },
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "Nqefupw8MO6E",
   "metadata": {
    "id": "Nqefupw8MO6E"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "phqEseYEMVB1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phqEseYEMVB1",
    "outputId": "4f38662b-8274-4120-be6c-a771d5f54fa0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.99834406, 'index': 1, 'word': 'a', 'start': 0, 'end': 1}, {'entity': 'B-PER', 'score': 0.99818975, 'index': 2, 'word': '##yman', 'start': 1, 'end': 5}, {'entity': 'B-ORG', 'score': 0.98740256, 'index': 9, 'word': 'wide', 'start': 34, 'end': 38}, {'entity': 'B-ORG', 'score': 0.72021335, 'index': 10, 'word': '##bot', 'start': 38, 'end': 41}]\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "example = \"Ayman applied for an intership at widebot\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K4mxDEzFMYmg",
   "metadata": {
    "id": "K4mxDEzFMYmg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
